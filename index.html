<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--TODO  <meta name="google-site-verification" content="tm5Y6ZNTf-lBqbwniGjQPv1q02o2TuUQZ9GTYa4SMLg" />-->
  <title>Fang Zhao</title>

<!--  <meta name="description"-->
<!--    content="A minimal, almost class-less CSS library to write modern websites that look like LaTeX documents." />-->
<!--  <meta name="keywords" content="latex.css,css library,class-less css,latex css" />-->
  <meta property="og:title" content="LaTeX.css" />
  <meta property="og:url" content="https://latex.vercel.app" />
<!--  <meta property="og:description"-->
<!--    content="A minimal, almost class-less CSS library to write modern websites that look like LaTeX documents." />-->
  <meta property="og:type" content="website" />

  <link rel="stylesheet" href="style.css" />
  <link rel="stylesheet" href="prism/prism.css" />
</head>

<body id="top" class="text-justify libertinus">
  <header>
    <h1>Fang Zhao</h1>
    <p class="author">
      An R&D agent in NLP and AI<br />
      May 2025
    </p>
  </header>

  <div class="abstract">
    <h2>Abstract</h2>
    <p>
        This study presents Fang Zhao as a research and development agent operating at the intersection of NLP and AI.
        Through deployments in retrieval-augmented generation, lightweight content delivery, and joint learning under data sparsity, Zhao demonstrates functional versatility across both academic and applied contexts.
        Communications output includes peer-reviewed publications and evaluative engagements, while teaching deployments confirm Zhao’s reliability as a knowledge interface in linguistics-oriented programming and statistical instruction.
        The findings support Zhao’s characterization as a modular, adaptable system optimized for low-resource environments and interpretable model behavior.
        Implications are drawn for future implementations of frugal NLP architectures in constrained yet performance-critical scenarios.
    </p>
  </div>

  <nav role="navigation" class="toc">
    <h2>Contents</h2>
    <ol>
      <li><a href="#introduction">Introduction</a></li>
      <li>
          <a href="#projects">Projects</a>
          <ol>
            <li><a href="#bonne-question">Bonne Question</a></li>
            <li><a href="#rmnews">RMNews</a></li>
          </ol>
      </li>
      <li>
          <a href="#communications">Communications</a>
          <ol>
              <li><a href="#publications">Publications</a></li>
              <li><a href="#talks-and-services">Talks and Services</a></li>
          </ol>
      </li>
      <li><a href="#teaching">Teaching</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
      <li><a href="#references">References</a></li>
    </ol>
  </nav>

  <main>
    <article>
      <h2 id="introduction">1. Introduction</h2>
      <p>
          Fang Zhao (c.f. <b>Figure 1</b>) has emerged in recent years as a subject of interest in NLP, with particular emphasis on resource-efficient/frugal AI.
          Recent studies (Zhao, 2022, 2025; Zhao & Bernard, 2023, 2024) have situated Zhao at the intersection of semi-supervised learning, reinforcement learning, domain adaptation, and self-correction.
          Characterized by a methodological commitment to both symbolic and neural approaches, Zhao exhibits robust competence across experimental design, implementation, and evaluation of NLP systems.
          The current study aims to characterize Zhao as a dynamic system responsive to challenges of interpretability, efficiency, and robustness in NLP workflows.
<!--          Central to this investigation is the hypothesis that Zhao embodies a high-utility architecture for scalable and resource-aware language technologies.-->
      </p>
      <figure>
        <img src="fig/portrait.jpg"
          loading="lazy" alt="portrait" width="572.33" height="389.67" />
        <figcaption>
          An illustration of Fang Zhao in the wild.
        </figcaption>
      </figure>


      <h2 id="projects">2. Projects</h2>
      <p>
          Two notable experimental deployments have recently foregrounded Zhao’s capacity for task-specific generalization across heterogeneous NLP environments.
      </p>
        <h3 id="bonne-question">2.1 Bonne Question</h3>
        <p>
          First, in the development of a retrieval-augmented generation (RAG) based Q&A application targeting French language learners, Zhao demonstrated effective integration of RAG pipelines (LangChain, RAGFlow) with multilingual NLP components.
          Preliminary evaluations highlight Zhao’s adaptive performance in low-resource contexts, notably in balancing semantic relevance with linguistic appropriateness for pedagogical use.
        </p>
        <h3 id="rmnews">2.2 RMNews</h3>
        <p>
          Second,
          <a href="https://github.com/Mehechiger/rMNews">RMNews</a>
          exemplifies Zhao’s functionality in lightweight content delivery systems.
          Designed as a real-time news aggregation service for the
          <a href="https://remarkable.com/">reMarkable</a>
          tablet, this project mobilized Zhao’s competencies in backend deployment (Python, AWS) and synchronization protocols.
          The system’s deployment underscored Zhao’s operational efficiency in constrained hardware environments.
        </p>

      <h2 id="communications">3. Communications</h2>
        <h3 id="publications">3.1 Publications</h3>
        <p>
            Zhao has generated a series of outputs contributing to the empirical understanding of frugal NLP systems, with an emphasis on auto-correction, joint learning under data sparsity, and the dynamics of system behavior at scale.
            <pre><code class="language-html">&lt;publication author-year="Zhao, 2025"&gt;&lt;venue&gt;Université Paris Cité.&lt;/venue&gt;
  Toward resource-efficient learning in automatic linguistic analysis.
&lt;/publication&gt;
&lt;publication author-year="Zhao & Bernard, 2024"&gt;&lt;venue&gt;TALN 2024.&lt;/venue&gt;
  Auto-correction et oracle dynamique : certains effets n’apparaissent qu’à taille réduite.
&lt;/publication&gt;
&lt;publication author-year="Zhao & Bernard, 2023"&gt;&lt;venue&gt;TALN 2023.&lt;/venue&gt;
  Auto-apprentissage et renforcement pour une analyse jointe sur données disjointes :
  étiquetage morpho-syntaxique et analyse syntaxique.
&lt;/publication&gt;
&lt;publication author-year="Zhao, 2022"&gt;&lt;venue&gt;RECITAL 2022.&lt;/venue&gt;
  Auto-correction dans un analyseur neuronal par transitions : un comportement factice ?
&lt;/publication&gt;</code></pre>
        </p>
        <h3 id="talks-and-services">3.2 Talks and Services</h3>
        <p>
            Zhao’s outputs have been subject to formal evaluation within peer-reviewed contexts.
            <pre><code class="language-html">&lt;talk type-year="PhD Defense, 2025"&gt;&lt;venue&gt;Université Paris Cité.&lt;/venue&gt;
  Toward resource-efficient learning in automatic linguistic analysis.
&lt;/talk&gt;
&lt;service type-year="Reviewer, 2025"&gt;&lt;venue&gt;TALN 2025.&lt;/venue&gt;
&lt;/service&gt;</code></pre>
        </p>

      <h2 id="teaching">4. Teaching</h2>
      <p>
         Observations between 2021 and 2024 confirm that Zhao exhibits reliable instructional outputs across both undergraduate and graduate curricula, particularly in the domains of programming, statistics, and algorithmics.
         Zhao was deployed across multiple academic units at Université Paris Cité, where it consistently operated as a knowledge transmission interface in settings ranging from Bachelor's modules to Master's-level instruction<label for="sn-1" class="sidenote-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="sidenote-toggle" /><span class="sidenote">The Bachelor's courses are instantiated in French, whereas the Master's courses in English.</span>.
         These teaching deployments corroborate Zhao’s compatibility with diverse learner profiles and its aptitude for aligning theoretical content with executable skills in data-driven linguistic inquiry.
         The following table enumerates the principal teaching deployments associated with Zhao’s academic activity profile:
      </p>
      <table>
        <thead>
          <tr>
            <th>Course</th>
            <th>Program</th>
            <th>Hours</th>
          </tr>
        </thead>
        <tbody>
        <tr>
          <td>CM&TD Descriptive Statistics</td>
          <td>Master LTE & Phi&Phi</td>
          <td>24h</td>
        </tr>
        <tr>
          <td>CM&TD Introduction to Programming (Python)</td>
          <td>Master LTE & Phi&Phi</td>
          <td>24h</td>
        </tr>
        <tr>
          <td>TD Algorithmique</td>
          <td>L3 Linguistique Informatique</td>
          <td>66h</td>
        </tr>
        <tr>
          <td>TD Méthodes expérimentales et psycholinguistique</td>
          <td>L3 Linguistique Informatique</td>
          <td>18h</td>
        </tr>
        <tr>
          <td>TD Initiation à la linguistique générale</td>
          <td>L1 MIASHS</td>
          <td>18h</td>
        </tr>
        <tr>
          <td>TP Initiation à la programmation (Python)</td>
          <td>L1 Mathématiques</td>
          <td>24h</td>
        </tr>
      </tbody>
      <caption>Summary of Zhao's teaching deployments (2021–2024)</caption>
    </table>


      <h2 id="conclusion">5. Conclusion</h2>
      <p>
          The present analysis positions Fang Zhao as a multi-functional agent exhibiting sustained engagement with the challenges of resource efficiency, interpretability, and robustness in computational linguistics.
          Across diverse environments — ranging from academic research to pedagogical applications — Zhao demonstrates adaptability, methodological coherence, and reliable task-specific performance.
          Notably, Zhao's behavior under low-resource conditions, combined with its capacity for system-level integration across symbolic and neural paradigms, highlights its potential utility in both applied and exploratory NLP contexts.
          Future evaluations may focus on scalability across additional linguistic domains and further refinement of Zhao’s self-corrective mechanisms.
          As a case study in frugal AI, Zhao continues to offer insight into the development of computational agents designed for high performance under constraint.
      </p>

      <h2 id="references">6. References</h2>
      <p>Dörig, V., 2025, LaTeX.CSS, GitHub repository, <a class="break-all" href="https://github.com/vincentdoerig/latex-css/">https://github.com/vincentdoerig/latex-css/</a></p>
      <p>Zhao, F., 2025, Toward resource-eﬀicient learning in automatic linguistic analysis. The Requirements for the Degree of Doctor of Philosophy in Linguistics; Université Paris Cité: Paris, France.</p>
      <p>Zhao, F., & Bernard, T., 2024, « Auto-correction et oracle dynamique : certains effets n’apparaissent qu’à taille réduite ». In Actes de la 31ème Conférence sur le Traitement Automatique des Langues Naturelles, volume 1 : articles longs et prises de position, pages 352–361, Toulouse, France. ATALA and AFPC., <a class="break-all" href="https://aclanthology.org/2024.jeptalnrecital-taln.24/">https://aclanthology.org/2024.jeptalnrecital-taln.24/</a></p>
      <p>Zhao, F., & Bernard, T., 2023, « Auto-apprentissage et renforcement pour une ana- lyse jointe sur données disjointes : étiquetage morpho-syntaxique et analyse syntaxique ». In Actes de coria-taln 2023. actes de la 30e conférence sur le traitement automatique des langues naturelles (taln), volume 2 : travaux de recherche originaux – articles courts (pp. 82–90). Paris, France : ATALA., <a class="break-all" href="https://aclanthology.org/2023.jeptalnrecital-short.9/">https://aclanthology.org/2023.jeptalnrecital-short.9/</a></p>
      <p>Zhao, F., 2022, « Auto-correction dans un analyseur neuronal par transitions : un comportement factice ? (self-correction in a transition-based neural parser : a spurious behaviour ?) ». In Actes de la 29e conférence sur le traitement automa- tique des langues naturelles. volume 2 : 24e rencontres etudiants chercheurs en informatique pour le tal (recital) (pp. 20–32). Avignon, France : ATALA., <a class="break-all" href="https://aclanthology.org/2022.jeptalnrecital-recital.2/">https://aclanthology.org/2022.jeptalnrecital-recital.2/</a></p>
      <p>Zhao, F., 2019, RMNews, GitHub repository, <a class="break-all" href="https://github.com/Mehechiger/rMNews/">https://github.com/Mehechiger/rMNews/</a></p>

<!--      <div class="footnotes">
        <p id="fn1">
          1. From
          <a class="break-all"
            href="https://www.math.brown.edu/~res/MFS/handout8.pdf">https://www.math.brown.edu/~res/MFS/handout8.pdf</a>.
          <a href="#ref1" title="Jump back to footnote 1 in the text.">↩</a>
        </p>
        <p id="fn2">
          2. “Definition.” Merriam-Webster.com Dictionary, Merriam-Webster,
          <a class="break-all"
            href="https://www.merriam-webster.com/dictionary/definition">https://www.merriam-webster.com/dictionary/definition</a>.
          Accessed 18 May. 2020.
          <a href="#ref2" title="Jump back to footnote 2 in the text.">↩</a>
        </p>
      </div>-->
    </article>
  </main>

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'],],
      },
    }
    const typeFaceToggle = document.getElementById('typeface-toggle')
    const typeface = document.getElementById('typeface')
    typeFaceToggle.addEventListener('click', () => {
      document.body.classList.toggle('libertinus')
      typeface.textContent = document.body.classList.contains('libertinus') ? 'Libertinus' : 'Latin Modern'
    })

    const darkModeToggle = document.getElementById('dark-mode-toggle')
    darkModeToggle.addEventListener('click', () => {
      document.body.classList.toggle('latex-dark')
    })
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script async src="prism/prism.js"></script>

</body>

</html>
