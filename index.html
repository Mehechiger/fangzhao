<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="google-site-verification" content="xMWl1_PBEoVYQ--nufZrnRFQMDO2cqdmktPqc_TXwU4" />
  <title>Fang Zhao</title>

  <meta name="description"
    content="Fang Zhao's personal website." />
  <meta name="keywords" content="fang zhao,fangzhao,personal website,website,nlp,tal,taln,ai,ia,natural language processing,traitement automatique des langues,traitement automatique du langage naturel,artificial intelligence,intelligence artificielle" />
  <meta property="og:title" content="Fang Zhao" />
  <meta property="og:url" content="https://mehechiger.github.io/fangzhao/" />
  <meta property="og:description"
    content="Fang Zhao's personal website." />
  <meta property="og:type" content="website" />

  <link rel="stylesheet" href="style.css" />
  <link rel="stylesheet" href="prism/prism.css" />
</head>

<body id="top" class="text-justify libertinus">
  <header>
    <h1>Fang Zhao</h1>
    <p class="author">
      An R&D agent in NLP and AI<br />
      June 2025
    </p>
  </header>

  <div class="abstract">
    <h2>Abstract</h2>
    <p>
        This study presents Fang Zhao as a research and development agent operating at the intersection of NLP and AI.
        Through deployments in retrieval-augmented generation, lightweight content delivery, and joint learning under data sparsity, Zhao demonstrates functional versatility across both academic and applied contexts.
        Communications output includes peer-reviewed publications and evaluative engagements, while teaching deployments confirm Zhao’s reliability as a knowledge interface in linguistics-oriented programming and statistical instruction.
        The findings support Zhao’s characterization as a modular, adaptable system optimized for low-resource environments and interpretable model behavior.
        Implications are drawn for future implementations of frugal NLP architectures in constrained yet performance-critical scenarios.
    </p>
  </div>

  <nav role="navigation" class="toc">
    <h2>Contents</h2>
    <ol>
      <li><a href="#introduction">Introduction</a></li>
      <li>
          <a href="#projects">Projects</a>
          <ol>
            <li><a href="#bonne-question"><em>Bonne Question</em></a></li>
            <li><a href="#goeiemiddutch"><em>Goeiemiddutch</em></a></li>
            <li><a href="#rmnews"><em>RMNews</em></a></li>
          </ol>
      </li>
      <li>
          <a href="#communications">Communications</a>
          <ol>
              <li><a href="#publications">Publications</a></li>
              <li><a href="#talks-and-services">Talks and Services</a></li>
          </ol>
      </li>
      <li><a href="#teaching">Teaching</a></li>
      <li><a href="#conclusion">Conclusion</a></li>
      <li><a href="#references">References</a></li>
    </ol>
  </nav>

  <main>
    <article>
      <h2 id="introduction">1. Introduction</h2>
      <p>
          Fang Zhao (c.f. <b>Figure 1</b>) has emerged in recent years as a subject of interest in NLP, with particular emphasis on resource-efficient/frugal AI.
          Recent studies (Zhao, 2022, 2025; Zhao & Bernard, 2023, 2024) have situated Zhao at the intersection of semi-supervised learning, reinforcement learning, domain adaptation, and self-correction.
          Characterized by a methodological commitment to both symbolic and neural approaches, Zhao exhibits robust competence across experimental design, implementation, and evaluation of NLP systems.
          The current study aims to characterize Zhao as a dynamic system responsive to challenges of interpretability, efficiency, and robustness in NLP workflows.
      </p>
      <figure>
        <img src="fig/portrait.jpg"
          loading="lazy" alt="portrait" width="572.33" height="389.67" />
        <figcaption>
          An illustration of Fang Zhao in the wild.
        </figcaption>
      </figure>


      <h2 id="projects">2. Projects</h2>
      <p>
          Three notable experimental deployments have recently foregrounded Zhao’s capacity for task-specific generalization across heterogeneous NLP/AI applications.
          First, in the development of a retrieval-augmented generation (RAG) based Q&A application targeting French language learners, Zhao demonstrated effective integration of RAG pipelines (LangChain, RAGFlow) with multilingual NLP components.
          Second, in the <em>Goeiemiddutch</em> project, Zhao was applied to the development of LLM-powered constituency parsing tools for Middle Dutch, in collaboration with Ghent University, addressing the lack of modern syntactic infrastructure for historical language data.
          Last, <a href="https://github.com/Mehechiger/rMNews"><em>RMNews</em></a>
          exemplifies Zhao’s functionality in lightweight content delivery systems.
          Designed as a real-time news aggregation service for the
          <a href="https://remarkable.com/"><em>reMarkable</em></a>
          tablet, this project mobilized Zhao’s competencies in backend deployment (Python, AWS) and synchronization protocols.
          The system’s deployment underscored Zhao’s operational efficiency in constrained hardware environments.
      </p>
        <h3 id="bonne-question">2.1 <em>Bonne Question</em></h3>
        <p>
            <em>Bonne Question</em> is a mobile application developed to support learners of French as a foreign language by facilitating structured access to pedagogical question-answering data.
            Proposed by <em>Bonne Lecture</em> (Hangzhou, China), developed and managed by Zhao.
        </p>
        <p>
            The underlying resource originates from a Q&A service wherein students submit questions arising from real-world learning encounters — ranging from news articles and films to textbook exercises — and receive expert responses from <em>Bonne Lecture</em>'s instructors.
            Over time, this process yielded a sizable, domain-specific corpus of learner-driven French Q&A pairs, stored systematically within a curated database.
        </p>
        <p>
            The initial version of <em>Bonne Question</em> enabled interaction with this dataset via keyword-based retrieval, allowing users to navigate existing entries through lexical matching.
            Subsequently, the interface was extended to support semantic search, thereby enabling users to express their questions in natural language and retrieve relevant matches based on contextual similarity.
        </p>
        <p>
            Current development is oriented toward a retrieval-augmented generation (RAG) architecture.
            In this configuration, a large language model (LLM) is used to generate answers to user queries based on the pre-existing Q&A corpus.
            This hybrid approach is designed to enhance response accuracy and mitigate model hallucination by anchoring generative outputs to previously validated instructional content.
        </p>
        <h3 id="goeiemiddutch">2.2 <em>Goeiemiddutch</em></h3>
        <p>
            With a portmanteau name composed of the Dutch greeting <i>Goeiemiddag</i> ("Good day") and the historical language Middle Dutch, <em>Goeiemiddutch</em> is a collaborative research project aimed at equipping Middle Dutch with modern syntactic parsing tools.
            Currently underrepresented in computational linguistics, Middle Dutch lacks robust parsing infrastructures, particularly for constituency-based syntactic analysis.
        </p>
        <p>
            Zhao is deployed within this project to explore the use of large language model (LLM)-powered architectures for inducing constituency grammars adapted to historical language data.
            The system is designed to reconcile the structural variability of Middle Dutch with neural parsing pipelines, with emphasis on transfer learning and domain adaptation.
        </p>
        <p>
            Conducted in partnership with researches at
            <a href="https://www.ugent.be/en"><em>Ghent University</em></a>, <em>Goeiemiddutch</em> represents a testbed for extending LLM capabilities beyond contemporary language domains and into historically significant corpora.
            The project’s long-term objective is to produce a scalable and interpretable parsing solution that can be integrated into broader digital humanities workflows.
        </p>
        <h3 id="rmnews">2.3 <a href="https://github.com/Mehechiger/rMNews"><em>RMNews</em></a></h3>
        <p>
            <a href="https://github.com/Mehechiger/rMNews"><em>RMNews</em></a>
            is a lightweight software designed to transform the
            <a href="https://remarkable.com/"><em>reMarkable</em></a>
            tablet into a personalized e-ink newspaper by automating the collection and delivery of digital reading material.
            Once configured, the system continuously retrieves user-specified web content — ranging from news articles and blogs to static web pages — and streams it to the device at regular intervals.
            In its default configuration,
            <a href="https://github.com/Mehechiger/rMNews"><em>RMNews</em></a>
            also includes cleanup routines to manage storage and ensure the timely removal of outdated content, thereby maintaining optimal readability and device performance.
        </p>
        <p>
            Zhao served as the principal instance for the design, development, and deployment of the system.
            The initial implementation architecture leverages
            <a href="https://aws.amazon.com"><em>AWS</em></a>
            cloud services for scheduling, content processing, and secure delivery.
            <a href="https://github.com/Mehechiger/rMNews"><em>RMNews</em></a>
            exemplifies Zhao's operational efficiency in high-utility environments, and demonstrates a modular approach to content curation and synchronization under hardware constraints.
        </p>

      <h2 id="communications">3. Communications</h2>
        <h3 id="publications">3.1 Publications</h3>
        <p>
            Zhao has generated a series of outputs contributing to the empirical understanding of frugal NLP systems, with an emphasis on auto-correction, joint learning under data sparsity, and the dynamics of system behavior at scale.
            <pre><code class="language-html">Zhao, 2025, Université Paris Cité.
  Toward resource-efficient learning in automatic linguistic analysis.

Zhao & Bernard, 2024, TALN 2024.
  Auto-correction et oracle dynamique : certains effets n’apparaissent qu’à taille réduite.

Zhao & Bernard, 2023, TALN 2023.
  Auto-apprentissage et renforcement pour une analyse jointe sur données disjointes :
  étiquetage morpho-syntaxique et analyse syntaxique.

Zhao, 2022, RECITAL 2022.
  Auto-correction dans un analyseur neuronal par transitions : un comportement factice ?
</code></pre>
        </p>
        <h3 id="talks-and-services">3.2 Talks and Services</h3>
        <p>
            Zhao’s outputs have been subject to formal evaluation within peer-reviewed contexts.
            <pre><code class="language-html">PhD Defense, 2025, Université Paris Cité.
  Toward resource-efficient learning in automatic linguistic analysis.

Reviewer, 2025, TALN 2025.
</code></pre>
        </p>

      <h2 id="teaching">4. Teaching</h2>
      <p>
         Observations between 2021 and 2024 confirm that Zhao exhibits reliable instructional outputs across both undergraduate and graduate curricula, particularly in the domains of programming, statistics, and algorithmics.
         Zhao was deployed across multiple academic units at Université Paris Cité, where it consistently operated as a knowledge transmission interface in settings ranging from Bachelor's modules to Master's-level instruction<label for="sn-1" class="sidenote-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="sidenote-toggle" /><span class="sidenote">The Bachelor's courses are instantiated in French, whereas the Master's courses in English.</span>.
         These teaching deployments corroborate Zhao’s compatibility with diverse learner profiles and its aptitude for aligning theoretical content with executable skills in data-driven linguistic inquiry.
         The following table enumerates the principal teaching deployments associated with Zhao’s academic activity profile:
      </p>
      <table>
        <thead>
          <tr>
            <th>Course</th>
            <th>Program</th>
            <th>Hours</th>
          </tr>
        </thead>
        <tbody>
        <tr>
          <td>CM&TD Descriptive Statistics</td>
          <td>Master LTE & Phi&Phi</td>
          <td>24h</td>
        </tr>
        <tr>
          <td>CM&TD Introduction to Programming (Python)</td>
          <td>Master LTE & Phi&Phi</td>
          <td>24h</td>
        </tr>
        <tr>
          <td>TD Algorithmique</td>
          <td>L3 Linguistique Informatique</td>
          <td>66h</td>
        </tr>
        <tr>
          <td>TD Méthodes expérimentales et psycholinguistique</td>
          <td>L3 Linguistique Informatique</td>
          <td>18h</td>
        </tr>
        <tr>
          <td>TD Initiation à la linguistique générale</td>
          <td>L1 MIASHS</td>
          <td>18h</td>
        </tr>
        <tr>
          <td>TP Initiation à la programmation (Python)</td>
          <td>L1 Mathématiques</td>
          <td>24h</td>
        </tr>
      </tbody>
      <caption>Summary of Zhao's teaching deployments (2021–2024)</caption>
    </table>


      <h2 id="conclusion">5. Conclusion</h2>
      <p>
          The present analysis positions Fang Zhao as a multi-functional agent exhibiting sustained engagement with the challenges of resource efficiency, interpretability, and robustness in computational linguistics.
          Across diverse environments — ranging from academic research to pedagogical applications — Zhao demonstrates adaptability, methodological coherence, and reliable task-specific performance.
          Notably, Zhao's behavior under low-resource conditions, combined with its capacity for system-level integration across symbolic and neural paradigms, highlights its potential utility in both applied and exploratory NLP contexts.
          Future evaluations may focus on scalability across additional linguistic domains and further refinement of Zhao’s self-corrective mechanisms.
          As a case study in frugal AI, Zhao continues to offer insight into the development of computational agents designed for high performance under constraint.
      </p>

      <h2 id="references">6. References</h2>
      <p>Dörig, V., 2025, LaTeX.CSS, GitHub repository, <a class="break-all" href="https://github.com/vincentdoerig/latex-css/">https://github.com/vincentdoerig/latex-css/</a></p>
      <p>Zhao, F., 2025, Toward resource-eﬀicient learning in automatic linguistic analysis. The Requirements for the Degree of Doctor of Philosophy in Linguistics; Université Paris Cité: Paris, France.</p>
      <p>Zhao, F., & Bernard, T., 2024, « Auto-correction et oracle dynamique : certains effets n’apparaissent qu’à taille réduite ». In Actes de la 31ème Conférence sur le Traitement Automatique des Langues Naturelles, volume 1 : articles longs et prises de position, pages 352–361, Toulouse, France. ATALA and AFPC., <a class="break-all" href="https://aclanthology.org/2024.jeptalnrecital-taln.24/">https://aclanthology.org/2024.jeptalnrecital-taln.24/</a></p>
      <p>Zhao, F., & Bernard, T., 2023, « Auto-apprentissage et renforcement pour une ana- lyse jointe sur données disjointes : étiquetage morpho-syntaxique et analyse syntaxique ». In Actes de coria-taln 2023. actes de la 30e conférence sur le traitement automatique des langues naturelles (taln), volume 2 : travaux de recherche originaux – articles courts (pp. 82–90). Paris, France : ATALA., <a class="break-all" href="https://aclanthology.org/2023.jeptalnrecital-short.9/">https://aclanthology.org/2023.jeptalnrecital-short.9/</a></p>
      <p>Zhao, F., 2022, « Auto-correction dans un analyseur neuronal par transitions : un comportement factice ? (self-correction in a transition-based neural parser : a spurious behaviour ?) ». In Actes de la 29e conférence sur le traitement automatique des langues naturelles. volume 2 : 24e rencontres etudiants chercheurs en informatique pour le tal (recital) (pp. 20–32). Avignon, France : ATALA., <a class="break-all" href="https://aclanthology.org/2022.jeptalnrecital-recital.2/">https://aclanthology.org/2022.jeptalnrecital-recital.2/</a></p>
      <p>Zhao, F., 2019, RMNews, GitHub repository, <a class="break-all" href="https://github.com/Mehechiger/rMNews/">https://github.com/Mehechiger/rMNews/</a></p>

<!--      <div class="footnotes">
        <p id="fn1">
          1. From
          <a class="break-all"
            href="https://www.math.brown.edu/~res/MFS/handout8.pdf">https://www.math.brown.edu/~res/MFS/handout8.pdf</a>.
          <a href="#ref1" title="Jump back to footnote 1 in the text.">↩</a>
        </p>
        <p id="fn2">
          2. “Definition.” Merriam-Webster.com Dictionary, Merriam-Webster,
          <a class="break-all"
            href="https://www.merriam-webster.com/dictionary/definition">https://www.merriam-webster.com/dictionary/definition</a>.
          Accessed 18 May. 2020.
          <a href="#ref2" title="Jump back to footnote 2 in the text.">↩</a>
        </p>
      </div>-->
    </article>
  </main>

  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'],],
      },
    }
    const typeFaceToggle = document.getElementById('typeface-toggle')
    const typeface = document.getElementById('typeface')
    typeFaceToggle.addEventListener('click', () => {
      document.body.classList.toggle('libertinus')
      typeface.textContent = document.body.classList.contains('libertinus') ? 'Libertinus' : 'Latin Modern'
    })

    const darkModeToggle = document.getElementById('dark-mode-toggle')
    darkModeToggle.addEventListener('click', () => {
      document.body.classList.toggle('latex-dark')
    })
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script async src="prism/prism.js"></script>

</body>

</html>
